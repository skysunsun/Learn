# 样本不均衡

简而言之，样本不均衡就是不同类别标签的样本之间的数量差别较大。

## 方法

### 收集更多的数据

收集更多的数据不仅能有效解决过拟合问题，收集更多的少类别样本更能够解决数据不均衡的问题。所以，遇到样本不均衡问题时，我们应该首先思考能否收集更多的数据。

**常用的数据数据增强手段有以下几点：**

1.  水平、垂直翻转
2.  翻转+旋转
3.  亮度、饱和度、对比度的随机变换
4.  随机裁剪
5.  随机缩放
6.  加模糊（blurring）
7.  加高斯噪声（Gaussian Noise）

除了前面三种之外，后面几种会改变数据的特征，需要谨慎使用。以下内容借鉴自：Kaggle经验：

需要小心的是，数据增强的样本点最好不要将原分布的变化范围扩大，比如训练集以及测试集的光照分布十分均匀，就不要做光照变化的数据增强，因为这样只会增加拟合新训练集的难度，对测试集的泛化性能提升却比较小。另外，新增加的样本点最好和原样本点有较大不同，不能随便换掉几个像素就说是一个新的样本，这种变化对大部分模型来说基本是可以忽略的。

对于这个卫星图像识别的任务来说，最好的数据增强方法是什么呢？显然是旋转和翻转。具体来说，我们对这个数据集一张图片先进行水平翻转得到两种表示，再配合0度，90度，180度，270度的旋转，可以获得一张图的八种表示。以人类的先验来看，新的图片与原来的图片是属于同一个分布的，标签也不应该发生任何变化，而对于一个卷积神经网络来说，它又是8张不同的图片。比如下图就是某张图片的八个方向，光看这些我们都没办法判断哪张图是原图，但显然它们拥有相同的标签。

img

其他的数据增强方法就没那么好用了，我们挑几个分析：

亮度，饱和度，对比度随机变化：在这个比赛的数据集中，官方已经对图片进行了比较好的预处理，亮度、饱和度、对比度的波动都比较小，所以在这些属性上进行数据增强没有什么好处。
随机缩放：还记得我们在Overview和Data部分看到的信息吗？这些图片中的一个像素宽大概对应3.7米，也不应该有太大的波动，所以随机缩放不会有立竿见影的增强效果。
随机裁剪：我们观察到有些图片因为边上出现了一小片云朵，被标注了partly cloudy，如果随机裁剪有可能把这块云朵裁掉，但是label却仍然有partly cloudy，这显然是在引入错误的标注样本，有百害而无一利。同样的例子也出现在别的类别上，说明随机裁剪的方法并不适合这个任务。
一旦做了这些操作，新的图片会扩大原样本的分布，所以这些数据增强也就没有翻转、旋转那么优先。在最后的方案中，我们只用了旋转和翻转。并不是说其他数据增强完全没效果，只是相比旋转和翻转，它们带来的好处没那么直接。

所以，在进行数据增强之前，需要仔细观察原始数据，观察其亮度、对比度等性质是否有较大的变化。依据结论进一步选择合适的数据增强方法。


### 数据集重采样

采样 采样是指对训练样本的取样，又分为上采样（Oversampling）和下采样（Undersampling）两种。上采样是从样本较少的类别中多次重复取样，下采样则是从样本较多的类别中部分取样。本质上，两种采样方法的目的都是从数据集层面使各个类别的样本比例趋于平衡。


3、数据集重采样
通过重采样，我们可以得到更多的数据样本已得到一个平衡的数据集。常用的采样方法有两种：

（1）复制样本数较少的类别的样本，这种方法称为over-sampling；
（2）删除样本数量较多的类别的样本，这种方法称为under-sampling.
这些方法都很简单而且易于实现。通常可以将这两种方法都进行尝试，看哪种方法得到的结果更好来做决定采用哪种方法。更多的可以参考 Oversampling and undersampling in data analysis.

一些经验：

当数据量较多的时候优先尝试under-sampling方法；
当数据量较少的时候优先尝试over-sampling方法；
使用随机或非随机（stratified，分层）采样策略；
尝试不同的采样比例而非固定的1:1.

### 样本合成
样本合成 样本合成最常见的方法是SMOTE（Synthetic Minority Oversampling Technique）。样本合成也是一种从数据集层面解决不均衡问题的方法。

4、合成样本
一个简单的合成样本的方法是随机的从数据量少的类别实例中随机挑选属性来生成样本。

你可以在数据集中凭经验对它们进行采样，或者也可以使用像Naive Bayes这样的方法，它可以在反向运行时独立地对每个属性进行采样。你将拥有更多不同的数据，但可能无法保留属性之间的非线性关系。

当然也可以使用系统算法生成合成样本。最流行的此类算法称为SMOTE (Synthetic Minority Over-sampling Technique). 正如它的名字一样，SMOTE是一个over-sampling方法，他通过样本数据较少类别的数据来合成新的数据而非简单的复制数据。该算法选择两个或更多个类似的实例（使用距离测量），并且对于差异内的相邻实例一次随机扰动实例一个属性。更多的关于SMOTE算法的内容，可以参考论文 SMOTE: Synthetic Minority Over-sampling Technique.

在Python中，在 UnbalancedDataset包中实现了SMOTE算法。

5. 通过组合、集成方法解决样本不均衡
组合/集成方法指的是在每次生成训练集时使用所有分类中的小样本量，同时从分类中的大样本量中随机抽取数据来与小样本量合并构成训练集，这样反复多次会得到很多训练集和训练模型。最后在应用时，使用组合方法（例如投票、加权投票等）产生分类预测结果。

### loss加权


3 更改损失函数-通过正负样本的惩罚权重解决样本不均衡
通过正负样本的惩罚权重解决样本不均衡的问题的思想是在算法实现过程中，对于分类中不同样本数量的类别分别赋予不同的权重（一般思路分类中的小样本量类别权重高，大样本量类别权重低），然后进行计算和建模。

使用Focal Loss
在机器学习任务中，除了会遇到严重的类别样本数不均衡问题之外，经常也会遇到容易识别的样本数目和难识别的样本数目不均衡的问题。为了解决这一问题，何凯明大神提出了Focal loss。

Focal loss尝试降低easy example对损失的贡献，这样网络会集中注意力在难样本上。

FL定义如下：

FL(p,p^)=−(α(1−p^)γplog(p^)+(1−α)p^γ(1−p)log(1−p^))
上述公式为二分类问题的Focal loss，可以看出对于每一个样本，使用(1−p^)γ作为其识别难易程度的指标，预测值p^越大代表对其进行预测越容易，因而其在总体损失中的占比应该越小。

对于多分类问题，其形式为：

FL(pt)=−αt(1−pt)γlog(pt)
对于每一个样本，pt为模型预测出其属于其真实类别的概率，αt可用于调节不同类别之间的权重。将λ设置为0便可以得到BCE。

使用加权损失
当样本分布不均衡时，我们可以依据先验知识给不同的类别赋予不同的损失权重，例如，可以使用加权的二维交叉熵损失，在pytorch实现的BCE损失函数中，提供了positive_weight参数用于指定各个类别对应的权重。假设训练集中，正类和负类的样本的比例为3:1，那么，可以将正类的比例设为0.75，负类的比例设为0.25。

loss加权 样本不均衡直接导致的结果是在计算loss的时候，样本较多的类别由于参与计算loss的贡献较多，导致预测能力失准。因此我们可以换一个角度，增加样本较少类别数据loss计算的权重。这个方法的难点在于需要手动设置合理的权重。
调研近几年关于样本不均衡问题的文献，推荐一篇发表于今年一月份的survey：Handling Imbalanced Data: A Survey，这篇paper从四个方面总结了最近几年比较新的imbalanced Data应对办法，下面作一下简单介绍。

focal_loss
dice_loss


### 改变模型评估方法
如上面说到的，当类别样本不均衡的时候，使用准确率作为评估标准往往很容易产生误导。此时我们可以采用别的评估方法，如kappa系数，ROC曲线，混淆矩阵，Recall，Precision，F1 Score等，更多可参见 Classification Accuracy is Not Enough: More Performance Measures You Can Use.

当某一类别的数据量远大于另一类别的样本数量时，我们就称其样本不均衡。数据类别样本本不均衡是机器学习中非常常见的一个问题，最常见的例子可能莫过于异常检测了。在异常检测中绝大部分样本都是正常类型的，只有极少部分属于异常。


### 尝试不同的算法
不同算法可能适用于不同的问题，因此对于同一个问题可以尝试使用不同的算法试试。话虽如此，决策树通常在不平衡的数据集上表现良好，用于创建树的类变量的拆分规则可有效解决这个问题。

6、使用罚分模型
附加罚分模型使用相同的算法但是提供了不同的视角。对于样本数较少的类别，罚分模型添加额外的损失（加大损失），这使得模型更加重视少样本类别的分类。

通常，类惩罚或权重的处理专用于学习算法。存在惩罚版本的算法，例如惩罚的SVM和惩罚的LDA。

当你的算法无法使用重采样来解决数据不平衡问题或结果很差时，使用罚分模型是非常有必要的。他提供了另一种处理数据不均衡的方法。然而，设置罚分矩阵很复杂，常常需要尝试很多次才能找到最佳策略。




7、尝试以更多不同的视角来看待样本不均衡问题
现在有很多关于样本不均衡问题的研究，他们都有自己的算法、评估方法、或者技术等。从不同的角度来思考数据不均衡问题可能带给我们不一样的结果。

两个可能需要考虑的是异常检测和变化检测。

异常检测是罕见事件的检测，这可能是由于偶然事件或由系统调用序列指示的程序的恶意活动而指示的机器故障。与正常操作相比，这些事件很少见。这种思维转变将次要类别视为异常类，这可能有助于考虑分离和分类样本的新方法。

变化检测类似于异常检测，除了寻找异常之外，它正在寻找变化或差异。这可能是使用模式或银行交易所观察到的用户行为的变化。

这两种转变都对分类问题采取了更为实际的立场，可能会为我们提供一些思考问题的新方法，也许还有一些尝试的技巧。

8、更具创造力
更加深入的思考所遇到的问题然后将问题分成一个个更容易解决的小问题。可以参考“In classification, how do you handle an unbalanced training set?”和 “Classification when 80% of my training set is of one class“.


4 使用样例挖掘

OHEM(online hard example mining)，即在线难例挖掘，指在训练过程中，只使用样本中损失较大的一部分样本进行网络的训练。

小结
其实，样本不均衡就是不同类别的数据不同使得模型学习时候偏向各个类别的权重不同，而我们要做的，其实就是如何均衡各个类别的权重，无论是上采样，下采样，抑或是更改loss，给数据量少的类别的loss给多权重，更直接的，在某些库的分类器中我们可以看到给某些样本直接赋予权重，这些虽然看起来不同，但是其实都是为了均衡权重这一目的而来的。

这些方法都不需要太多的数学理论知识，你所需要做的仅仅只是挑出一种方法，然后开始尝试，直到找到最好的方法。

新增（2020.1.31）
在看宗成庆老师的《统计自然语言处理》时，书中讲到文本情感分类数据不平衡时谈到了几个已有的方法，感觉还不错，因此摘过来。

基于中心向量的不平衡数据分类方法
该方法包括以下几个步骤对不平衡数据的标注样本进行训练：

（1）将‘多类’（即数据量较多的类别）里面的所有训练样本进行聚类；
（2）在各个聚类里面进行内部层次采样，获得同“少类”相同规模的样本；
（3）使用这些采样样本并结合整个类（个人理解应该是聚类后的各个类）的中心向量构建的新向量进行训练学习。
该方法借鉴中心向量充分利用‘多类’里面所有样本的分类信息，可获得比传统采样方法更好的结果。

基于协同学习的半监督学习方法
该方法有如下两个特点：

（1）使用欠采样技术对训练样本进行平衡采样，用于构建多个欠采样分类器，利用多个分类器对非标注样本进行标注；
（2）采用动态特征子空间的方式，即每次迭代重新生成特征子空间，增加分类器的之间的差异性，进一步提升学习器的性能。
去掉其非监督标注部分，其实此方法就是在数据较多的类别中多次取样然后与少数据的类别一起训练多个分类器（每个分类器有一个类别的样本不同，然后分类时各个分类器又使用不同的特征），其思想与随机森林较为相像。













