# 使用64位数据进行Pytorch训练

Pytorch默认使用单精度float32训练模型，原因在于：使用float16训练模型，模型效果会有损失，而使用double(float64)会有2倍的内存压力，且不会带来太多的精度提升。

```python
torch.set_default_dtype(torch.float64)
```
