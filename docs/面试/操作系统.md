
>栈区（stack）— 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。

>堆区（heap） — 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表。

>全局区（静态区）（static）—，全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 - 程序结束后由系统释放。

>文字常量区 —常量字符串就是放在这里的。 程序结束后由系统释放

>程序代码区—存放函数体的二进制代码。


# 什么是操作系统？

1. 操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的软件程序，是计算机系统的内核与基⽯；
3. 操作系统为⽤户提供⼀个与系统交互的操作界⾯ ；
4. 操作系统分内核与外壳（我们可以把外壳理解成围绕着内核的应⽤程序，⽽内核就是能操作硬件的程序）。

## 用户态和内核态

​	在计算机系统中，分两种程序：系统程序和应用程序，为了保证系统程序不被应用程序有意或无意地破坏，为计算机设置了两种状态——用户态、内核态

**用户态：** 只能受限的访问内存，运行所有的应用程序

**内核态：** 运行操作系统程序，cpu可以访问内存的所有数据，包括外围设备


### 用户态切换到内核态的3种方式：

​	**系统调用**

​		这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现。

​	**异常**

​		当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

​	**外围设备的中断**

​		当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

> 这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。


## 操作系统内存管理方式，分页分段以及段页式的优缺点

**存管理方式：**块式管理、页式管理、段式管理、段页式管理

### 分段管理：

​		在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）


>外部碎片：随着进程装入和移出内存，空闲的内存空间被分为小片段，当所有的空闲的这些小片段的内存之和可以满足请求，但是并不连续的时候，这个时候就会出现外部碎片的问题，这个问题可能会很严重，这个就是外部碎片

#### 解决外部碎片问题的方法

1. 紧缩法，紧缩的目的就是移动内存内容，以便所有空闲空间合并成一整块，但是紧缩并不是所有的程序都是可以的，因为如果重定位是静态的，也就是说在汇编时或装入内存的时候进行的，那么就不能紧缩，紧缩只是在重定位是动态并且在运行时可以采用，如果地址被动态重定位，就可以去移动程序和数据，然后去根据新基地址的值来改变基地址寄存器，如果我们采用了紧缩，我们还要去估计其的开销，最简单的合并算法就是去将所有进程移动内存的一端，而将所有的孔移动到内存的另一端，这样以生成一个大的空闲快，不过这种方案的开销大

2. 还有一种就是可以是允许物理地址空间为非连续，这样的话，我们只需要有物理地址就可以为进程去分配空间了

### 分页管理：

​		在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的页框，程序加载时，可以将任意一页放入内存中任意一个页框，这些页框不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）

>内部碎片:通常将内存以固定大小的块为单位来分配，进程所分配的内存可能要比所要的要大，这两个数字之差就称为内部碎片，这部分内存在分区当中，不过不能使用

### 段页式管理：

​		段⻚式管理机制结合了段式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若干段，每个段⼜分成若干页，也就是说段⻚式管理机制中段与段之间以及段的内部的都是离散的。

**共同点** ：
   - 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
   - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

**区别** ：
   - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
   - 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。



### 页置换算法


**置换算法：** 先进先出FIFO、最近最久未使用LRU、最佳置换算法OPT

**先进先出FIFO:**

​		原理：把内存中驻留时间最久的页面置换算法予以淘汰

​		优点：实现简单、直观

​		缺点：没有考虑到实际的页面使用频率，性能差、与通常页面使用的规则不符合，实际应用较少

​		改进：给每个页面增加一个R位，每次先从链表头开始查找，如果R置位，清除R位并且把该页面节点放	到链表结尾；如果R是0，那么就是又老又没用到，替换掉。

**最近最久未使用LRU:**

​		原理：选择最近且最久未使用的页面进行淘汰

​		优点：考虑到了程序访问的时间局部性，有较好的性能，实际应用也比较多

​		缺点：实现需要比较多的硬件支持，会增加一些硬件成本
```python
class LRUCache(collections.OrderedDict):

    def __init__(self, capacity: int):
        super().__init__()
        self.capacity = capacity


    def get(self, key: int) -> int:
        if key not in self:
            return -1
        self.move_to_end(key)
        return self[key]

    def put(self, key: int, value: int) -> None:
        if key in self:
            self.move_to_end(key)
        self[key] = value
        if len(self) > self.capacity:
            self.popitem(last=False)
```

**最佳置换算法OPT:**

​		原理：每次选择当前物理块中的页面在未来长时间不被访问的或未来不再使用的页面进行淘汰

​		优点：具有较好的性能，可以保证获得最低的缺页率

​		缺点：过于理想化，但是实际上无法实现（没办法预知未来的页面）



### CPU 寻址

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件。如下图所示：

![](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/2b27dac8cc647f8aac989da2d1166db2.png)

>逻辑(虚拟)地址：我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。

>物理地址: 指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

### 为什么要有虚拟地址空间呢？

1. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，**造成操作系统崩溃。**
2. 程序地址一般是从1开始编号，直接访问物理地址会造成冲突，**使得同时运行多个程序特别困难。**比如你想同时运行一个微信和一个 QQ ：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。


### 快表

为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把块表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。


### 多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以查看下面这篇文章

- 多级页表如何节约内存：[https://www.polarxiong.com/archives/多级页表如何节约内存.html](https://www.polarxiong.com/archives/多级页表如何节约内存.html)

### [什么是虚拟内存(Virtual Memory)?](https://zh.wikipedia.org/wiki/虚拟内存)

**虚拟内存** 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等。


### 虚拟内存的技术实现

1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟内存的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**


### 请求分页与分页存储管理，两者有何不同呢？

它们之间的根本区别在于是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。


### 虚拟存储器

基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——**虚拟存储器**。

### 局部性原理

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。



## 进程

一个运行的程序(代码)就是一个进程,没有运行的代码叫程序,进程是系统资源分配的最小单位,进程拥有自己独立的内存空间,所以进程间数据不共享,开销大.


### 进程分配的资源包括哪些

1. 标识相关：pid，ppid等等
2. 文件相关：进程需要记录打开的文件信息，于是需要文件描述符表
3. 内存相关：内存指针，指向进程的虚拟地址空间（用户空间）信息
4. 优先级相关：进程相对于其他进程的调度优先级
5. 上下文信息相关：CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，当内核需要切换到另一个进程时，需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。
6. 状态相关：进程当前的状态，说明该进程处于什么状态
7. 信号相关：进程的信号处理函数，以及记录当前进程是否还有待处理的信号
8. I/O相关：记录进程与各种I/O设备之间的交互

### 进程间通信方式IPC

**匿名管道pipe：**

​		匿名管道是半双工的，数据只能单向通信；需要双方通信时，需要建立起两个管道；只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）。

**命名管道FIFO：**

​		不同于匿名管道之处在于它提供一个路径名与之关联，以FIFO的文件形式存在于文件系统中。这样，即使与FIFO的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过FIFO相互通信（能够访问该路径的进程以及FIFO的创建进程之间），因此，通过FIFO不相关的进程也能交换数据。值得注意的是，FIFO严格遵循先进先出（first in first out），对管道及FIFO的读总是从开始处返回数据，对它们的写则把数据添加到末尾。

**信号：**

​		信号是一种比较复杂的通信方式，信号产生的条件：按键、硬件异常、进程调用kill函数将信号发送给另一个进程、用户调用kill命令将信号发送给其他进程，信号传递的消息比较少，主要用于通知接收进程某个时间已经发生。

**消息队列：**

​		消息队列是消息的链表，存放在内核中并由消息队列标识符标识，消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点。消息队列起信箱作用，到了就挂在那里，需要的时候去取。消息队列提供了一种在两个不相关进程间传递数据的简单有效的方法。与命名管道相比：消息队列的优势在于，它独立于发送和接收进程而存在，这消除了在同步命名管道的打开和关闭时可能产生的一些困难。消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。而且，每个数据块被认为含有一个类型，接收进程可以独立地接收含有不同类型值的数据块。

​	**优点：**

​		A. 我们可以通过发送消息来几乎完全避免命名管道的同步和阻塞问题。

​		B. 我们可以用一些方法来提前查看紧急消息。

​	**缺点：**

​		A. 与管道一样，每个数据块有一个最大长度的限制。

​		B. 系统中所有队列所包含的全部数据块的总长度也有一个上限。

**共享内存(share memory)：**

- 使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。
- 为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。
- 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。

**信号量(Semaphores) ：**

​		信号量是⼀个计数器，⽤于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信⽅式主要⽤于解决与同步相关的问题并避免竞争条件。

**套接字(Sockets) :** 

​		此⽅法主要⽤于在客户端和服务器之间通过⽹络进⾏通信。套接字是⽀持TCP/IP 的⽹络通信的基本操作单元，可以看做是不同主机之间的进程进⾏双向通信的端点，简单的说就是通信的两⽅的⼀种约定，⽤套接字中的相关函数来完成通信过程。


### 进程调度算法

- **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
- **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。


### 进程切换要保存的信息

上下文信息

上下文包括：

通用目的寄存器
浮点寄存器
程序计数器
用户栈
状态寄存器
内核栈
各种内核数据结构：比如描绘地址空间的页表，包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表。





## 线程

调度执行的最小单位,也叫执行路径,不能独立存在, 依赖进程存在. 一个进程至少有一个线程,叫主线程,而多个线程共享内存(数据共享,共享全局变量),从而极大地提高了程序的运行效率.


### 线程共享的信息包含哪些

堆：　是大家共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏。

地址空间

全局变量

打开的文件

子进程

闹铃

记账信息

### 线程独有的信息有哪些

栈：是个线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立，因此，栈是　thread safe的。操作系统在切换线程的时候会自动的切换栈，就是切换　ＳＳ／ＥＳＰ寄存器。栈空间不需要在高级语言里面显式的分配和释放。

程序计数器

全局变量

寄存器

栈

状态字

### 线程池

在使用多线程处理任务时也不是线程越多越好。因为在切换线程的时候，需要切换上下文环境，线程很多的时候，依然会造成CPU的大量开销。为解决这个问题，线程池的概念被提出来了。

预先创建好一个数量较为优化的线程组，在需要的时候立刻能够使用，就形成了线程池。在Python中，没有内置的较好的线程池模块，需要自己实现或使用第三方模块。

### 孤儿进程

父进程退出, 子进程还在运行的这些子进程都是孤儿进程, 孤儿进程将被init进程(进程号为1)所收养, 并由init进程对他们完成状态收集工作.

### 僵尸进程

进程使用fork创建子进程, 如果子进程退出, 而父进程并没有调用wait或waitpid获取子进程的状态信息,那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程


#### 怎么避免僵尸进程?

1. fork 两次用孙子进程去完成子进程的任务;
·   
2. 用wait()函数使父进程阻塞

3. 使用信号量, 在signal handler 中调用waitpid, 这样父进程不用阻塞.


### 线程间的同步的方式

1. **互斥量(Mutex)：** 采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. **信号量(Semphares)：** 它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
3. **事件(Event) Wait/Notify：** 通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较

### 什么是多线程竞争?如何解决？

同一个进程里线程是数据共享的,当各个线程访问数据资源时会出现竞争状态即:数据几乎同步会被多个线程占用,造成数据混乱,即所谓的线程不安全

一般使用锁机制解决

### 什么是锁?有哪几种锁?

 锁(Lock)是Python提供的对线程控制的对象,有互斥锁,可重入锁,死锁.

**锁的好处:** 确保了某段关键代码(共享数据资源)只能由一个线程从头到尾完整地执行能解决多线程资源竞争下的原子操作问题.

**锁的坏处:** 阻止了多线程并发执行,包含锁的某段代码实际上只能以单线程模式执行,效率就大大地下降了

**锁的致命问题:死锁**

### 什么是死锁?

若干子线程在资源竞争时,都在等待对方对某部分资源解除占用状态,结果是谁也不愿先解锁,互相干等着,程序无法执行下去,这就是死锁.


​**形成死锁的条件：**

- 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；

- 请求与保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源

- 非剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放

- 循环等待条件：系统中若干进程组成环路，环路中每个进程都在等待相邻进程占用的资源

​**解决方法：** 

- 破坏死锁的任意一条件

- 资源一次性分配，从而剥夺请求和保持条件

- 可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件

- 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件

### GIL锁,全局解释器锁(只有在cpython里才有)

作用: 限制多线程同时执行,保证同一时间只有一个线程执行,所以cpython里的多线程其实是伪多线程

所以Python里常常使用协程技术来代替多线程,协程是一种更轻量级的线程.

进程和线程的切换是由系统决定的,而协程由我们程序员自己决定,而模块gevent下切换是遇到了耗时操作才会切换


### 多线程与多进程区别

|维度|多进程|多线程|总结|
| :----: | :----: | :----: | :----: |
|数据共享、同步|数据是分开的:共享复杂，需要用IPC; 同步简单|多线程共享进程数据：共享简单；同步复杂|各有优势|
|内存、CPU|占用内存多，切换复杂，CPU利用率低|占用内存少，切换简单，CPU利用率高|线程占优|
|创建销毁、切换|创建销毁、切换复杂，速度慢 |创建销毁、切换简单，速度快 |线程占优| 
|编程调试|编程简单，调试简单|编程复杂，调试复杂|进程占优 |
|可靠性|进程间不会相互影响 |一个线程挂掉将导致整个进程挂掉|进程占优|
|分布式 |适应于多核、多机分布 ；如果一台机器不够，扩展到多台机器比较简单|适应于多核分布|进程占优|


### 进程切换复杂体现在什么地方

最主要的一个区别在于进程切换涉及虚拟地址空间的切换而线程不会。因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。

现在我们已经知道了进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用Cache来缓存常用的地址映射，这样可以加速页表查找，这个cache就是TLB（translation Lookaside Buffer，我们不需要关心这个名字只需要知道TLB本质上就是一个cache，是用来加速页表查找的）。由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么当进程切换后页表也要进行切换，页表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程线程无需切换地址空间，因此我们通常说线程切换要比较进程切换块，原因就在这里。

### linux中用top、ps命令查看进程中的线程
```shell
ps -T -p <pid>

Top
```

### 线程是并发还是并行?进程是并发还是并行?

线程是并发, 进程是并行

>并行(parallel) : 同一时刻多个任务同时在运行.

>并发(concurrency):在同一时间间隔内多个任务都在运行, 但是并不会在同一时刻同时运行, 存在交替执行的情况

### Python中的进程与线程的使用场景?

多进程适合在CPU密集型操作(CPU指令比较多, 如位数多的浮点运算).

多线程适合在IO密集型操作(读写数据操作较多的, 比如爬虫)

协程的适用场景：当程序中存在大量不需要CPU的操作时（IO），适用于协程；


## 协程

是一种用户态的轻量级线程,协程的调度完全由用户控制.协程拥有自己的寄存器上下文和栈.协程调度切换时,将寄存器上下文和栈保存到其他地方,在切回来的时候,恢复先前保存的寄存器上下文和栈,直接操作栈则基本没有内核切换的开销,可以不加锁的访问全局变量,所以上下文的切换非常快

Python中一般使用`asyncio`库实现


>三者的关系: 进程里有线程,线程里有协程.

###  协程切换快的原因

1. 协程切换完全在用户空间进行，线程切换涉及特权模式切换，需要在内核空间完成；
2. 协程切换相比线程切换做的事情更少。

## 同步,异步, 非阻塞

同步: 多个任务之间有先后顺序执行,一个执行完下个才能执行.

异步:多个任务之间没有先后顺序,可以同时执行 有时候一个任务可能在必要的时候获取另一个同时执行的任务的结果,这就叫回调!

阻塞: 如果卡住了调用者,调用者不能继续往下执行,就是说调用者阻塞了

非阻塞:如果不会卡住, 可以继续执行,就是说非阻塞的

同步异步相对于多任务而言,阻塞非阻塞相对于代码执行而言


# 集群与分布式

分布式是指通过网络连接的多个组件，通过交换信息协作而形成的系统。而集群，是指同一种组件的多个实例，形成的逻辑上的整体。

![al9p0P.jpg](https://s1.ax1x.com/2020/07/31/al9p0P.jpg)

# 参考：
> - https://github.com/Snailclimb/JavaGuide/blob/master/docs/operating-system/basis.md
> - https://github.com/pure-xiaojie/JavaInterview/blob/master/README.md
> - https://www.jianshu.com/p/c1015f5ffa74