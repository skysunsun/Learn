# 用于显着物体检测的非局部深度特征

## 针对问题

>   显着性检测旨在突出图像中最相关的对象。使用传统模型的方法很难在突出的背景上描绘显着的物体，而深度神经网络具有过度的复杂性和缓慢的评估速度。

>   为了实现最先进的性能，表现最佳的CNN模型需要非常重要的步骤，例如生成对象提议，应用后处理，通过使用超像素或定义复杂的网络架构，同时使预测远比实时慢。
>   因此，仍有机会简化模型架构并加快计算速度。

>   CNNs最初是为了进行图像分类而开发的。这些模型由一系列具有非线性激活函数的卷积层和最大池化操作组成，一直到预测每个类的可能性的softmax层。由于CNN方法的输出是一个k-
>   d向量(其中k是类的数量)，而不是人们所期望的一个N\*M映射(其中N
>   \*M是输入图像的大小)，因此它先天不适合预测显著性映射。然而，我们可以通过在每个像素周围提取一个正方形的patch来缓解这个问题，并使用这个patch来预测中心像素的类。为了让这些方法捕获一个超出每个patch范围的全局上下文，它们处理从输入图像的不同分辨率中提取的patch

## 提出模型

>   在本文中，提出了一种简化的卷积神经网络，它通过多个方式结合局部和全局信息。展示了最先进的CNN模型的总体目标(加强预测显著性地图的空间一致性，并在优化中使用局部和全局特征)可以通过一个非常简化的非局部深度特征(NLDF)模型来实现。受Mumford-Shah
>   (MS)函数启发，通过贝叶斯损失来加强空间一致性。损失表示为交叉熵项和边界项之和。与传统的MS函数实现不同，我们使用通过深度网络学习的非本地特性，而不是原始的RGB颜色。而且，我们不是直接最小化边界长度(就像无监督的MS实现那样)，而是最小化使用预测和地面真值边界像素计算的联合损失的交集。边界惩罚项对模型的性能有显著的影响。由于我们的方法不依赖于超像素，所以它是完全卷积的，因此达到了类内最佳的计算速度。我们的模型网络由以4×5网格组织的卷积和反卷积块组成，其中网格的每列提取分辨率特定的特征。沿着每个分辨率轴也使用局部对比度处理块，以便促进具有强烈局部对比度的特征。生成的局部和全局特征组合成一个“得分”处理块，最终输出为输入分辨率的一半。

### 架构

![](media/a80dcc69072a97238acaf3da53f90dac.png)

1.  第一行为VGG-16（卷积1到卷积5）最后接了一个卷积计算全局上下文

2.  第二行计算不同分辨率的图像，第三行计算不同分辨率的对比度（使用当前减去平均的方法计算），第三行和第四行用到了一个跳层结构

3.  第四行为反卷积层，即上采样（综合局部特征）

4.  局部和全局联合计算显著性概率

>   **各层参数：**

![](media/ba1f70489918895016a9a7e1c75ad276.png)

>   **损失函数：**

![](media/41070e3f59439ba663b60c29c6f0b63b.png)

>   左边是普通的交叉熵损失函数，右边是边界损失函数（利用边界像素计算），
>   为正加权常数

## 效果

>   在MSRA-B数据集上训练了我们的模型，并对其进行了测试,六种不同的显着性基准数据集。
>   结果表明我们的方法与最先进的技术相同，同时还原计算时间为18至100倍，接近实时，高性能显着性检测

>   NLDF模型在0.08s内对输入图像进行评估，与其他最先进的深度学习方法相比，速度增益为18到100倍，同时在MSRAB[30]、HKU-IS[25]、PASCAL-S[27]、DUT-OMRON[49]、ECSSD[48]和SOD[32]基准数据集上与最先进的评估性能保持一致。

>   文中对比了有边界损失和没有边界损失的结果，有边界损失更能让预测更加完整

## 优缺点

### 优点：

>   使用单个完全卷积的CNN。
>   使用一系列多尺度卷积和反卷积块组织成一个新颖的5×4网格。模型确保输出具有正确的大小，同时捕获本地和全局上下文以及各种分辨率的功能。基于Mumford-Shah模型启发的损失函数实现空间相关性，

>   巧妙的加入了对比度的计算，巧妙的加入了边界损失函数；没有预处理和后处理，时间节省，实时检测

>   每个像素周围提取一个正方形的patch，并使用这个patch来预测中心像素的类

>   缺点：

>   我还是觉模型大……………

1.  改进想法

2.  模型减小：

    1.  最大特征层有640了，想减小特征层数

    2.  还有反卷积层和全局计算用了5\*5卷积核，想改为3\*3

3.  对比度计算用的是平均池化，显著性是突出部分，想用最大池化试一试。

4.  模型中第二行到第四行的跳层结构。

5.  关于损失函数的两个超参数设置？文中两个都设置的1

6.  文中所说的patch块代替一部分区域，这个patch块到底取多大的问题？

7.  图像还有空间的信息，考虑到把空间信息加入到损失函数中。
