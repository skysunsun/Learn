---
title: 论文笔记-MEnet
commentable: True
data: 2019-04-13
mathjax: true
tags: 显著性检测
---

# [A Metric Expression Network for Salient Object Segmentation](https://arxiv.org/pdf/1805.05638.pdf)（一种用于突出目标分割的度量表达式网络）

## 针对问题

1.传统的显着性检测模型的底层特征主要包括颜色、强度、纹理和结构，虽然带有启发式先验的手工制作的特性在简单场景中表现良好，但它们对更具挑战性的情况(比如突出区域与背景颜色相似时)并不健壮。

2.神经网络的性能容易受到噪声等典型畸变的影响。

## 模型结构

该文受度量学习框架的启发，提出了一个适用于学习度量空间的显著性模型。用于潜在不良图像的显著性分割。使用从深度CNN中提取的语义特征来学习齐次度量空间。

### 特征编码器

该文提出了和SegNet和U-net类似的模型结构：采用编解码器提取多尺度特征。由于全局信息在显著性分割中起着重要的作用，使用卷积和池化层来增加模型的接受域，最后将所有的特征信息压缩成大小为$1\times1$的特征图
在每个向下采样的步骤中，该文使用了步长为2的卷积将特征通道的数量增加一倍。

### 特征解码器

通过解码器模块，对这些特征图进行上采样，每个尺度上的特征图表示一个语义级别上的信息。解码器的每个步骤包括将输入与短连接连接之后通过反卷积对特征图进行上采样。类似与Unet。但不同的是：
*U-net是为边缘检测而设计的，即使它从编码器路径中截取特征图也能很好地工作，因为它不影响边缘检测。*
而对于显著性分割，文中保持特征图的大小以充分利用所有的信息，因为它的接受域需要更大。文中认为$1\times1$尺寸的特征图包含了原始图像丰富的全局信息，可以为以后的图层提供更好的预测。

因此，该文提出了一种对称的CNN编解码器结构:一个编码-解码器CNN首先生成不同尺度(块)的特征图，通过卷积和上采样，根据图像在层间的映射方式为图像的每个像素提供一个特征向量。然后将这些提取的特征通过卷积用于度量损失和交叉熵函数中，用于显著性检测。
![EChlWR.png](https://s2.ax1x.com/2019/04/20/EChlWR.png)

基本的结构

![EChQY9.png](https://s2.ax1x.com/2019/04/20/EChQY9.png)

文中使用对称CNN的目标是生成不同尺度的特征，这些特征被连接起来，为输入图像中包含跨维度多尺度信息的每个对应像素提供特征向量。
此外，该模型使用更多的卷积来平衡维度不均匀性，而没有直接分类。
模型的最终目的想要区分突出的物体和背景，因此将图像像素映射到一个特征空间，在这个空间中，突出区域和背景区域之间的距离很大，但区域内的距离很小。深度CNNs可以学习这样一种特征表示，它可以捕获局部和全局上下文信息，用于显著性分割

编码器-解码器网络的13个不同尺度的块转换成一组特征图，也就是说，在特征提取部分，每个尺度通过一次卷积和上采样，生成一个大小相同的输出特征图;

#### 超列模型

在训练超列模型时，通过叠加额外的卷积层，从不同尺度的特征图预测热图。
在测试超列模型时，取所有这些层的输出，使用双线性插值对它们进行上采样，并将它们求和，以得到最终的预测结果。
超列模型更像DHSNet，它利用多尺度显著性标签进行分割。

相反，MEnet在训练过程中对相同大小的特征图的每一个尺寸进行上采样。由于这些具有13个尺度的特征的分量之间是不均匀的，不能直接应用于分类。这些来自不同尺度的分量应该是平衡的，一种可能的方法是通过卷积来过滤这些13维的特征。因此，在将每一层的特征图连接起来后，我们进一步使用16个核的卷积运算来生成最终的特征图，以最小化交叉熵为约束来平衡维度特征。

## 损失函数
### 交叉熵损失函数

$L_{C E}(l | \theta_{1})=-\frac{1}{N \times|\Omega|}\sum_{n=1}^{N} \sum_{i=1}^{\Omega} \sum_{y=0}^{1} 1\{l_{i}^{(n)}=y\} \ln P(l_{i}^{(n)}=y | \theta_{1})$

#### 参数说明
$\theta_1$为影响网络$l$的可学的参数集
$\Omega$为图像的像素域
$1\{.\}$为指标函数
$y=1$为突出像素，$y=0$为非突出像素。
$P(l_{i}^{(n)}=y | \theta_{1})$是网络预测的第$i$个像素的标签概率。
在MEnet中，从特征提取部分与2个卷积核进行计算得到$P(l_{i}^{(n)}=y | \theta_{1})$

### 度量损失函数
受度量学习的启发，该文引入度量损失函数(ML)，度量损失函数定义如下:

$L_{M L}(f | \theta_{2})=\frac{1}{N \times|\Omega|} \sum_{n=1}^{N} \sum_{i=1}^{\Omega}(\frac{1}{|\operatorname{set}^{+}|}.\sum_{k \in s e t^{+}}\|f_{i}^{(n)}-f_{k}^{(n)}\|_{2}^{2}-\frac{1}{|s e t^{-}|} \sum_{k \in \operatorname{set}^{-}}\|f_{i}^{(n)}-f_{k}^{(n)}\|_{2}^{2} )$

#### 参数说明：

$\theta_2$为影响网络${f}$的可学的参数集
${f(n)}$为训练集的第${n}$个图像的像素的特征向量
${k\in{set^+}}$.${k\in{set^-}}$.$\Omega=(set^+\cup set^-)$
${f_k}^{(n)}$是${f_i}^{(n)}$的正特征或者负特征，他们来自同一个区域，要么显著，要么非先显著

该损失函数寻求一种编码-解码器网络，该网络可以增大来自不同区域的任意一对特征向量之间的距离，并减小来自同一区域的距离。这样一来，这两个区域本身应该是齐次的。它等价于:
$L_{M L}^{*}(f | \theta_{2})=\frac{1}{N \times|\Omega|} \sum_{n=1}^{N} \sum_{i=1}^{\Omega}(\|f_{i}^{(n)}-\overline{f_{+}}^{(n)}\|_{2}^{2}.-\|f_{i}^{(n)}-\overline{f_{-}}^{(n)}\|_{2}^{2} )$

#### 参数说明

从${f_k}^{(n)}$获得${\bar{f_+}^{(n)}}$和${\bar{f_{-}}^{(n)}}$
${\bar{f_+}^{(n)}}$是所有正样本的平均
${\bar{f_{-}}^{(n)}}$是所有负样本的平均

### 最终损失函数
在显著特征空间中，同一区域提取的特征向量距离该区域的中心较近，而距离其他区域的中心较远。在这种情况下，可以得到一个更加鲁棒的突出目标和背景之间的距离评估。我们还在目标函数中加入了第二个交叉熵损失函数作为约束，该约束具有相同的网络结构，因此，最终的损失函数定义如下：
${L_{MEnet}({f,l|\theta})}={L_{ML}^{*}}({f}|\theta_2)+\lambda{L_{CE}(l|\theta_1)}$

#### 参数说明

$\theta=\theta_1+\theta_2$
$\lambda=1$

### 语义距离转换
训练MEnet使损失函数最小化，则得到收敛网络$T_\theta^*$，其中$\theta^*$是$\theta$的收敛状态。给定要测试的输入图像，其中像素域为$\Omega$，我们通常描述像素$i\in\Omega$通过它的强度$I_i$在通道上传播。但是，用$d_{ij}^{I_\Omega}=d(I_i,I_j)$来定义语义距离是比较困难的。如$d_{i,j}=\parallel{I_i-I_j}\parallel_2$,然而，通过$T_{\theta^*}$的变换，将得到相应的特征向量$\{f_i\}_{i\in\Omega}$表示输入。距离可以用$d_{i,j}^{'}=d_{ij}^{T_{\theta^*}(I_\Omega)}=\parallel{f_i-f_j}\parallel_2$,最后的显著图$S$通过如下公式获得:

$\begin{aligned} S_{i} &=\|f_{i}-E_{f_{j} \sim P_{B}(\cdot)} f_{j}\|_{2} \\ &=\|f_{i}-\sum_{j \in \Omega_{B}} P_{B}(f_{j}) f_{j}\|_{2} \end{aligned}$

#### 参数说明
$P_B(.)$是特征向量$f_j\in\Omega_B$的概率分布函数
$\Omega=\Omega_B\cup\Omega_S$，$\Omega_B$和$\Omega_S$表示仅由损失函数中的$L_{CE}$分量计算得到的整个收敛网络$T_{\theta^*}$内的背景区域和显著区域。
但是$\Omega_B$和$\Omega_S$不是精确的分割，在实验部分还有待进一步研究。最后，通过网络变换，我们成功地表达了$d_{ij}^{I_\Omega}$与$d_{ij}^{T_{\theta}*(I_\Omega)}$

## 思考
### 好的地方
1. 建议的模型是从零开始训练的，不需要预处理/后处理。
2. 特征空间的映射
3. 多尺度
4. 像素特征减去均值
5. 最后的输出是基于损失函数算出来的
6. 虽然没有详细描述基础架构的详细设计，但是架构的设计融合了跳层设计和多尺度融合

### 不好的地方
1. 像素级别的计算，似乎很拖慢计算速度
2. 虽然用到像素级的信息计算，但是文中也说到背景和显著性区域没有精确分割
3. 交叉损失和ML度量损失是分开算的
4. 对于网络的基本的结构设计文中没有详细说明
